<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introducing breakaway â€¢ breakaway</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">breakaway</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="..//index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/breakaway.html">Get Started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/betta-figure.html">Comparing samples visually with betta</a>
    </li>
    <li>
      <a href="../articles/getting-started.html">Getting started with breakaway</a>
    </li>
    <li>
      <a href="../articles/sample-size-calculations.html">Sample size calculations for alpha diversity</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Introducing breakaway</h1>
                        <h4 class="author">Amy Willis</h4>
            
            <h4 class="date">2017-09-21</h4>
          </div>

    
    
<div class="contents">
<p>The introduction to alpha diversity workshop that I teach at STAMPS at the Marine Biological Laboratory. Lots of problems that I need to fix! Hence all of the comments.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(breakaway)

###### bettademo.R, a script to introduce you to the package "breakaway"
###### for alpha diversity estimation and comparison
###### Software authors: Amy Willis and Kathryn Barger
###### Theory &amp; paper authors: Amy Willis, Kathryn Barger &amp; John Bunge, 2013-15

## Start by checking what directory you are in with
<span class="kw">getwd</span>()</code></pre></div>
<pre><code>## [1] "/Users/adwillis/Documents/software/breakaway/docs/articles"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Set it to your local copy of diversitylab with setwd("[folder/diversitylab]")

## Load the package we need. It's called breakaway. It's awesome.
## Conflicts of interest alert: I wrote it.
<span class="kw">require</span>(<span class="st">"breakaway"</span>)
## If the above didn't work, check that the file is in the same location
## as getwd()
## If that didn't work, check you can connect to the internet, have
## a look at your CRAN mirror settings...
## If you're still having trouble, call a TA over!

<span class="co"># #### Load the species abundance table and metadata</span>
<span class="co"># data &lt;- read.table("mask_data.txt",header=T)</span>
<span class="co"># metadata &lt;- read.table("mask_meta.txt",header=T)</span>
<span class="co"># ## If an error was thrown, that means that the data was not in the</span>
<span class="co"># ## working directory. Ensure that the data is in filepath specified by</span>
<span class="co"># ## getwd(), or setwd([where you have saved your data])</span>
<span class="co"># </span>
<span class="co"># ## This is data from 63 different lakes.</span>
<span class="co"># </span>
<span class="co"># ## Have a look at the first few rows/columns your data and your metadata</span>
<span class="co"># data[1:4,1:4]</span>
<span class="co"># metadata[1:4,]</span>
<span class="co"># ## data is very big! To see how big, go</span>
<span class="co"># dim(data)</span>
<span class="co"># </span>
<span class="co"># ## Huh? Levels? What type of object is Year, anyway?</span>
<span class="co"># class(metadata$Year)</span>
<span class="co"># ## Year is what's called a "Factor," i.e. a categorical variable. But</span>
<span class="co"># ## what if we want to consider it as a continuous variable? We need to</span>
<span class="co"># ## force it into a numeric. We do this as follows</span>
<span class="co"># Year_num &lt;- as.numeric(substr(as.character(metadata$Year),4,5))</span>
<span class="co"># Year_num</span>
<span class="co"># ## Feel like you're falling behind? Don't stress! If you want to learn the</span>
<span class="co"># ## details you can go back later and figure out exactly what the functions</span>
<span class="co"># ## as.character, substr, and as.numeric all do, and why I chose to combine</span>
<span class="co"># ## them in this way.</span>
<span class="co"># </span>
<span class="co"># ## Take a moment to congratulate yourself on loading a package,</span>
<span class="co"># ## opening data, and exploring the dataset! That's huge! Woohoo!</span>
<span class="co"># </span>
<span class="co"># ##### CREATE FREQUENCY TABLES</span>
<span class="co"># </span>
<span class="co"># ## We're now going to "collapse" the data's columns (samples) into frequency tables</span>
<span class="co"># ## We use several functions here: table, apply, as.data.frame and lapply</span>
<span class="co"># ## If you're interested, you should explore these later. We want to analyse</span>
<span class="co"># ## the data right now!</span>
<span class="co"># frequencytablelist &lt;- lapply(apply(data,2,table),as.data.frame)</span>
<span class="co"># frequencytablelist &lt;- lapply(frequencytablelist,function(x) x[x[,1]!=0,])</span>
<span class="co"># </span>
<span class="co"># ## Have a look at the frequency tables ("frequency count data"). I've put them</span>
<span class="co"># ## in a list so we need to use double square brackets [[63]] to refer to the 63rd one</span>
<span class="co"># frequencytablelist[[63]]</span>
<span class="co"># ## Interpretation: In this sample, there were 57 different species observed</span>
<span class="co"># ## only once (singletons), 25 different species observed only twice, ...,</span>
<span class="co"># ## 1 species observed 171 times</span>
<span class="co"># </span>
<span class="co"># ##### ESTIMATE SPECIES RICHNESS</span>
<span class="co"># ## Let's run breakaway on the first frequency count table</span>
<span class="co"># breakaway(frequencytablelist[[1]])</span>
<span class="co"># ## You should get some output to screen, including your estimate &amp; s.e., and a</span>
<span class="co"># ## plot of the fits to the ratios. Note that it is not a fit to the frequencies,</span>
<span class="co"># ## it is a fit to the ratios of frequencies. You would never need to include</span>
<span class="co"># ## this type of plot in one of your papers. It is solely for you to check</span>
<span class="co"># ## for model misspecification. What's model misspecification? If the black</span>
<span class="co"># ## diamonds don't remotely follow the pattern of the white circles, that's</span>
<span class="co"># ## model misspecification.</span>
<span class="co"># </span>
<span class="co"># ## The reference for breakaway is</span>
<span class="co"># ## Willis, A. and Bunge, J. (2015). Estimating Diversity via Frequency Ratios. Biometrics 71 1042-1049.</span>
<span class="co"># ## Feel free to email me with questions!</span>
<span class="co"># </span>
<span class="co"># ## Sometimes, breakaway's usual procedure doesn't work, that is, it gives</span>
<span class="co"># ## a negative estimate, which is of course silly. In that case, breakaway</span>
<span class="co"># ## returns a different model's result. It's called the WLRM. There isn't a</span>
<span class="co"># ## picture. Here is an example of a case where breakaway returns the WLRM.</span>
<span class="co"># breakaway(frequencytablelist[[60]])</span>
<span class="co"># ## breakaway can defer to the WLRM for several reasons. Perhaps there are</span>
<span class="co"># ## too many singletons. Perhaps there isn't a long enough tail. Perhaps</span>
<span class="co"># ## there is false diversity. In this case, there was probably not enough data.</span>
<span class="co"># ## Let's see if this failure was sensitive to the singleton count by running</span>
<span class="co"># ## breakaway_nof1. This requires no singleton count (implicit is that the</span>
<span class="co"># ## singleton count was erroneous) and predicts it from the other frequencies.</span>
<span class="co"># ## Here is an example.</span>
<span class="co"># breakaway_nof1(frequencytablelist[[60]][-1,])</span>
<span class="co"># </span>
<span class="co"># ## The reference for this method:</span>
<span class="co"># ## Willis, A. (2016). Species richness estimation with high diversity but spurious singletons.</span>
<span class="co"># </span>
<span class="co"># ## breakaway_nof1 is an exploratory tool for assessing sensitivity of</span>
<span class="co"># ## breakaway to the singleton count. You should not use it for diversity</span>
<span class="co"># ## estimation -- only diversity *exploration* :)</span>
<span class="co"># </span>
<span class="co"># </span>
<span class="co"># </span>
<span class="co"># </span>
<span class="co"># ## Let's move on to looking at the Objective Bayes procedures of</span>
<span class="co"># ## Kathryn Barger. It's the latest and greatest in diversity estimation!</span>
<span class="co"># </span>
<span class="co"># ## There are 4 different types of objective bayes estimates, due to</span>
<span class="co"># ## 4 different models. If you have time play with all of them!</span>
<span class="co"># ## For now we are just going to look at the negative binomial.</span>
<span class="co"># </span>
<span class="co"># #objective_bayes_poisson(frequencytablelist[[60]])$results</span>
<span class="co"># #objective_bayes_geometric(frequencytablelist[[60]])$results</span>
<span class="co"># #objective_bayes_mixedgeo(frequencytablelist[[60]])$results</span>
<span class="co"># </span>
<span class="co"># install.packages("MASS"); require(MASS) ## you need MASS for this to work</span>
<span class="co"># objective_bayes_negbin(frequencytablelist[[1]])</span>
<span class="co"># ## (Don't worry about those warnings. We're working on them -- sorry!)</span>
<span class="co"># </span>
<span class="co"># ## That's a lot of information! Bayesians are very good at generating</span>
<span class="co"># ## a lot of information. This is because rather than a single estimate</span>
<span class="co"># ## you see the distribution of estimates (remember that the Bayesian</span>
<span class="co"># ## paradigm believes the parameter to be random =&gt; it has a distribution)</span>
<span class="co"># </span>
<span class="co"># </span>
<span class="co"># ## Let's talk about some of the information:</span>
<span class="co"># # $results mode.N/mean.N/median.N : the mode/mean / median estimate</span>
<span class="co"># # $results L/UCI.N:  A 95% percent interval estimate for the richness</span>
<span class="co"># # The picture at the bottom: The distribution of estimates</span>
<span class="co"># </span>
<span class="co"># ## The reference for this method is</span>
<span class="co"># ## Barger &amp; Bunge. (2010). Objective Bayesian estimation for the number</span>
<span class="co"># ##    of species. Bayesian Analysis. 5(4), 765-785.</span>
<span class="co"># </span>
<span class="co"># ## EVENNESS</span>
<span class="co"># </span>
<span class="co"># ## The above discussion focused exclusively on richness. Let's look at</span>
<span class="co"># ## the variability of evenness estimates</span>
<span class="co"># </span>
<span class="co"># ## Let's calculate the plug in estimate of Shannon diversity</span>
<span class="co"># shannon(frequencytablelist[[1]])</span>
<span class="co"># </span>
<span class="co"># ## 4.95, huh? Let's look at how variable it is</span>
<span class="co"># set.seed(2) # the following functions are random, so let's set the seed (allows reproducibility)</span>
<span class="co"># resample_estimate(data[,1], shannon)</span>
<span class="co"># resample_estimate(data[,1], shannon)</span>
<span class="co"># resample_estimate(data[,1], shannon)</span>
<span class="co"># </span>
<span class="co"># ## Hmmm, doesn't look too variable! Let's look at a lot of them</span>
<span class="co"># par(mfrow=c(1,1))</span>
<span class="co"># hist(replicate(200, resample_estimate(data[,1], shannon)))</span>
<span class="co"># ## (replicate says: "do this 200 times")</span>
<span class="co"># ## Yikes, that's some negative skew! That suggests that we have</span>
<span class="co"># ## risks in randomly observing really low Shannon diversity estimates</span>
<span class="co"># ## This is an important thing to keep in mind when analysing data</span>
<span class="co"># ## eg. Did we just have bad luck with the sample from the patient</span>
<span class="co"># ##     taking the drug? Or is the drug causing the effect?</span>
<span class="co"># </span>
<span class="co"># ## BTW, you can use the above to look sample size variability as well</span>
<span class="co"># ## If you have very different numbers of reads across samples, this can$</span>
<span class="co"># ## introduce additional variability. Let's look at the distribution</span>
<span class="co"># ## of reads in the current dataset.</span>
<span class="co"># ns &lt;- unlist(lapply(frequencytablelist, function(x) sum(x[,2])))</span>
<span class="co"># hist(ns)</span>
<span class="co"># ## Well, but a lot of variability! Lets account for it in looking at</span>
<span class="co"># ## our distribution of Shannon diversity estimates</span>
<span class="co"># set.seed(8)</span>
<span class="co"># hist(replicate(500, resample_estimate(data[,1], shannon, my_sample_size = ns)))</span>
<span class="co"># ## That's a lot more variability than we saw originally!</span>
<span class="co"># </span>
<span class="co"># ## Going forward with your analyses, don't forget to account for</span>
<span class="co"># ## variability in your estimates. Bootstrap standard errors are better</span>
<span class="co"># ## than nothing!</span>
<span class="co"># sd(replicate(500, resample_estimate(data[,1], shannon, my_sample_size = ns)))</span>
<span class="co"># </span>
<span class="co"># </span>
<span class="co"># ###### COMPARISONS</span>
<span class="co"># </span>
<span class="co"># ## We spent a lot of time looking at each sample'salpha diversity values</span>
<span class="co"># </span>
<span class="co"># ## Let's do some comparisons across samples... accounting for variability</span>
<span class="co"># ## of course!</span>
<span class="co"># </span>
<span class="co"># ## We're going to do this procedure for shannon evenness, and estimate</span>
<span class="co"># ## it using the plug-in estimate. This is not meant to imply that you should </span>
<span class="co"># ## be interested in Shannon! Just that some people are.</span>
<span class="co"># </span>
<span class="co"># ## Feel free to substitute in whatever alpha diversity/evenness/richness</span>
<span class="co"># ## procedure you're interested in!</span>
<span class="co"># </span>
<span class="co"># ## To do this we will start by iterating on Shannon on every one of our samples.</span>
<span class="co"># ## It may take a minute or two to run. Feel like a stretch? Go ahead!</span>
<span class="co"># </span>
<span class="co"># ## This section may take a while. Do you know if your neighbour likes bagels?</span>
<span class="co"># ## Would they order a croissant over a bagel? Now is a great time to find out!</span>
<span class="co"># estimates_shannon &lt;- matrix(NA,nrow=dim(data)[2],ncol=4)</span>
<span class="co"># rownames(estimates_shannon) &lt;- colnames(data)</span>
<span class="co"># colnames(estimates_shannon) &lt;- c("shannon_est","shannon_seest","shannon_lcb","shannon_ucb")</span>
<span class="co"># for (i in 1:dim(data)[2]) {</span>
<span class="co">#   #resample_estimate(data[,i], shannon, my_sample_size = ns)</span>
<span class="co">#   samples &lt;- replicate(500, resample_estimate(data[,i], shannon, my_sample_size = ns))</span>
<span class="co">#   estimates_shannon[i,1] &lt;- mean(samples)</span>
<span class="co">#   estimates_shannon[i,2] &lt;- sd(samples)</span>
<span class="co">#   estimates_shannon[i,3:4] &lt;- quantile(samples, c(0.025, 0.975))</span>
<span class="co"># }</span>
<span class="co"># ## Here gives us our estimates and standard errors so we can have a look</span>
<span class="co"># estimates_shannon[,1:2]</span>
<span class="co"># ## We can even (normal-ish) plot intervals. The x-axis is just against the</span>
<span class="co"># ## enumeration of the lakes. It is not meaningful.</span>
<span class="co"># ## The following plotting command may be different to ones you have seen</span>
<span class="co"># ## before. It's a really quick way of visualizing the error in your samples</span>
<span class="co"># ## and quickly spotting outliers. NOTE: Outliers have SMALL LINES, which means</span>
<span class="co"># ## high precision, and are generally far away from points near them.</span>
<span class="co"># betta_pic(estimates_shannon[,1], estimates_shannon[,2])</span>
<span class="co"># </span>
<span class="co"># ## No obvious outliers here.</span>
<span class="co"># </span>
<span class="co"># ## Lets look at the effect of summer samples</span>
<span class="co"># col_by_seasons &lt;- ifelse(metadata$Season=="Autum","black",ifelse(metadata$Season=="Spring","pink","red"))</span>
<span class="co"># betta_pic(estimates_shannon[,1], estimates_shannon[,2], mycol = col_by_seasons)</span>
<span class="co"># legend("bottom",c("Spring","Summer","Autumn"),col=c("pink","red","black"),cex=0.8,lwd=3,box.col=F)</span>
<span class="co"># ## Don't forget that because we are plotting diversity *estimates*, we</span>
<span class="co"># ## need to plot *lines* (i.e. confidence intervals) not points (point</span>
<span class="co"># ## estimates). That's very important.</span>
<span class="co"># </span>
<span class="co"># </span>
<span class="co"># ## We're now going to create our "design" matrix, a.k.a. "X matrix."</span>
<span class="co"># ## To do this we're going to cheat a little. We're going to use an</span>
<span class="co"># ## existing R method, lm, to save us the hassle.</span>
<span class="co"># ## We are going to investigate the effect of temperature and site</span>
<span class="co"># covar_matrix &lt;- model.matrix(lm(rnorm(dim(metadata)[1])~metadata$Site*(metadata$Season=="Summ")))</span>
<span class="co"># head(covar_matrix)</span>
<span class="co"># colnames(covar_matrix) &lt;- c("Int", "SiteP", "Summer", "SitePSummer")</span>
<span class="co"># ## Details (skip if uninterested): lm(y~x+z) is a function that fits a</span>
<span class="co"># ## regression line to y using the variables x and z. It has a very nice</span>
<span class="co"># ## interface that saves you doing the hard work (aka "math") to create your</span>
<span class="co"># ## design matrix. The function we are going to use has no such nice interface.</span>
<span class="co"># ## For that reason, we steal the design matrix out of lm()'s implementation.</span>
<span class="co"># ## lm(y~x*z) looks at interactions. In this case, we are seeing if the</span>
<span class="co"># ## evenness trend as a function of temperature changes depending on the site</span>
<span class="co"># </span>
<span class="co"># ## Easter egg: if you can put your own data (from your own research) in the</span>
<span class="co"># ## *exact* same form as the above example, you don't need to understand what</span>
<span class="co"># ## happens below. You can just copy it :)</span>
<span class="co"># ## Hint: The biggest problem you may have in implementing the above is</span>
<span class="co"># ## the ordering of the data and the metadata. The following:</span>
<span class="co"># colnames(data)==rownames(metadata)</span>
<span class="co"># ## being true in every spot is a necessary but not sufficient condition for</span>
<span class="co"># ## the following to work properly.</span>
<span class="co"># </span>
<span class="co"># #### MODEL SPECIES RICHNESS, TEST SIGNIFICANCE, INTERPRET RESULTS</span>
<span class="co"># ## Let's go ahead and try to fit our model</span>
<span class="co"># results &lt;- betta(estimates_shannon[,1],estimates_shannon[,2],covar_matrix)</span>
<span class="co"># ## Let's take a look at the results</span>
<span class="co"># results$table</span>
<span class="co"># ## Interpretation is idential to regression.</span>
<span class="co"># </span>
<span class="co"># ## Here are some things to quickly note:</span>
<span class="co"># ## Firstly, significance of Summer means that the average</span>
<span class="co"># ## Shannon diversity of the summer samples is significantly</span>
<span class="co"># ## less than non-summer AT SITE L. It's less by 0.42 on</span>
<span class="co"># ## average.</span>
<span class="co"># </span>
<span class="co"># ## The non-signif of the SiteP variables means there</span>
<span class="co"># ## is no significant difference between Sites P and L,</span>
<span class="co"># ## in both summer and not... AFTER ACCOUNTING FOR </span>
<span class="co"># ## ESTIMATION ERROR!</span>
<span class="co"># </span>
<span class="co"># ## Notice that a regression on the Shannon estimates</span>
<span class="co"># ## notes more evidence against the "site has no affect" null:</span>
<span class="co"># summary(lm(estimates_shannon[,1] ~ metadata$Site*(metadata$Season=="Summ")))$coef[,c(1,4)]</span>
<span class="co"># ## Not such a big deal in this case, but may be with more</span>
<span class="co"># ## marginal results/more variables.</span>
<span class="co"># </span>
<span class="co"># ## You should always use betta() when modelling and doing</span>
<span class="co"># ## inference on functions of your OTU table!</span>
<span class="co"># </span>
<span class="co"># ## sigsq_u (in full results output) being significant means there is still *heterogeneity*</span>
<span class="co"># ## in the lakes. "Not all lakes have the same Shannon diversity</span>
<span class="co"># ## even after accounting for season &amp; site."</span>
<span class="co"># ##  (microscale heterogeneity, pH, chemical factors, depth...?)</span>
<span class="co"># </span>
<span class="co"># </span>
<span class="co"># ## If you are unfamiliar with regression analysis, we would recommend</span>
<span class="co"># ## taking an introductory course in regression analysis. You will</span>
<span class="co"># ## not regret it (after some period of time)!</span>
<span class="co"># </span>
<span class="co"># ####### Congratulations! You have finished almost all of the tutorial!</span>
<span class="co"># </span>
<span class="co"># ## An important note: I'm not pushing Shannon.</span>
<span class="co"># ## You can repeat all of the above analysis with your own</span>
<span class="co"># ## favourite index. Suppose I am more interested in</span>
<span class="co"># ## Simpson, or inverse Simpson, or Shannon adjusted for population size.</span>
<span class="co"># ## Here is how I would do this:</span>
<span class="co"># </span>
<span class="co"># ## Define a function to take otu columns and estimate</span>
<span class="co"># ## the Simpson index using the plug-in estimate</span>
<span class="co"># simpson  &lt;-  function(data) {</span>
<span class="co">#   data &lt;- data/sum(data)</span>
<span class="co">#   sum(data^2)</span>
<span class="co"># }</span>
<span class="co"># </span>
<span class="co"># ## Exercise: define a function to calculate the inverse</span>
<span class="co"># ## of the plug-in Simpson index  estimate</span>
<span class="co"># </span>
<span class="co"># ## To estimate the bootstrap mean and standard error</span>
<span class="co"># ## of the simpson index, we do the following</span>
<span class="co"># simpson_resamples &lt;- replicate(100, resample_estimate(data[,1], simpson))</span>
<span class="co"># hist(simpson_resamples)</span>
<span class="co"># mean(simpson_resamples)</span>
<span class="co"># sd(simpson_resamples)</span>
<span class="co"># </span>
<span class="co"># ## this is just for the first column</span>
<span class="co"># ## you would do this for every sample (in a loop)</span>
<span class="co"># ## then use these as inputs to betta</span>
<span class="co"># </span>
<span class="co"># ## The below shows you how to run CatchAll and read the output into R</span>
<span class="co"># ## CatchAll is very fussy, because it was built for an outdated operating system</span>
<span class="co"># ##</span>
<span class="co"># </span>
<span class="co"># ##### CATCHALL</span>
<span class="co"># ## CatchAll is computionally intensive. For this reason, we will run it</span>
<span class="co"># ## on only 4 of the samples.</span>
<span class="co"># ## We are going to create a directory to write our frequency tables to,</span>
<span class="co"># ## write our frequency tables, run CatchAll on them, read the CatchAll</span>
<span class="co"># ## output back into R, then analyze the same data again using the</span>
<span class="co"># ## CatchAll richness estimates</span>
<span class="co"># </span>
<span class="co"># ## We are going to be clever and run command line commands via</span>
<span class="co"># ## R. So the below command is equivalent to writing "mkdir catchalltables"</span>
<span class="co"># ## in the command line.</span>
<span class="co"># system("mkdir catchalltables")</span>
<span class="co"># for (i in 1:4) {</span>
<span class="co">#   tmp &lt;- frequencytablelist[[i]] ## catchall is really fussy! Need numbers not strings/factors</span>
<span class="co">#   tmp2 &lt;- cbind(as.numeric(levels(tmp[,1]))[-1],tmp[,2])</span>
<span class="co">#   write.table(tmp2,paste(getwd(), "/catchalltables/",</span>
<span class="co">#                          names(frequencytablelist)[i],".csv",sep=""),sep=",",row.names = FALSE,col.names = FALSE)</span>
<span class="co"># }</span>
<span class="co"># system("cp runcatchall.sh catchalltables")</span>
<span class="co"># system("cp CatchAllCmdL.exe catchalltables")</span>
<span class="co"># ## This next step runs CatchAll on every file; it may take a few minutes</span>
<span class="co"># system("cd catchalltables; ./runcatchall.sh")</span>
<span class="co"># </span>
<span class="co"># ### IF THIS DIDN'T WORK *and* YOU WANT TO LEARN TO USE CATCHALL**</span>
<span class="co"># ## 1. If you're on a Ma/Unix: You probably don't have mono (an emulator)</span>
<span class="co"># ##    Go to http://www.mono-project.com/ and install it. </span>
<span class="co"># ## 2. If you're on Windows: Hmmm. You're going to need a different version. </span>
<span class="co"># ##    Download CatchAllcmdW.exe from http://www.northeastern.edu/catchall/downloads.html</span>
<span class="co"># ##    Then run CatchAllcmdW.exe [inputfilename] [outputpath]</span>
<span class="co"># ## 3. If neither of the above help: Sorry! Call me/a TA over. Or, come back to</span>
<span class="co"># ##    it later and open up butterfly_BestModelsAnalysis.csv (an example output)</span>
<span class="co"># ##    to see</span>
<span class="co"># </span>
<span class="co"># ## ** If CatchAll isn't so important, feel free to check out. You've learnt</span>
<span class="co"># ## a lot already!</span>
<span class="co"># </span>
<span class="co"># ## We just ran CatchAll without interfacing with the command line.</span>
<span class="co"># ## Woohoo! Now we'll read them in.</span>
<span class="co"># </span>
<span class="co"># ## We tell R to search in the directory "catchalltables" for any files ending</span>
<span class="co"># ## in "*BestModelsAnalysis.csv" We then pull out the relevant columns</span>
<span class="co"># ## into a matrix called estimates_catchall</span>
<span class="co"># txt.sources = list.files(path=paste(getwd(),"/catchalltables/",sep=""),</span>
<span class="co">#                          pattern="*BestModelsAnalysis.csv",recursive=TRUE)</span>
<span class="co"># myread &lt;- function(x)  {</span>
<span class="co">#   y &lt;- read.csv(paste("catchalltables/",x,sep=""),stringsAsFactors=FALSE)</span>
<span class="co">#   return(as.numeric(y[1,4:7]))</span>
<span class="co"># }</span>
<span class="co"># estimates_catchall &lt;- matrix(sapply(txt.sources,myread),byrow=TRUE,ncol=4)</span>
<span class="co"># rownames(estimates_catchall) &lt;- paste("Sample", 1:4, sep="")</span>
<span class="co"># colnames(estimates_catchall) &lt;- c("catchall_est","catchall_seest","catchall_lcb","catchall_ucb")</span>
<span class="co"># estimates_catchall</span>
<span class="co"># </span>
<span class="co"># ## We can now run betta in the same way!</span>
<span class="co"># betta(estimates_catchall[,1], estimates_catchall[,2])$table</span>
<span class="co"># ## Note that these estimates are homogeneous (all the same!)</span>
<span class="co"># ## probably because there are only 4</span>
<span class="co"># ## Here we haven't included any covariates (it's unlikely that we</span>
<span class="co"># ## could find anything meaningful with 4 data points), but if you did</span>
<span class="co"># ## this with your own data you would include covariates in the same</span>
<span class="co"># ## way that we did for breakaway.</span>
<span class="co"># </span>
<span class="co"># ## THANKS FOR STAYING THROUGH TO THE END! I'd love to hear if you</span>
<span class="co"># ## hated it/loved it/worst day ever -- please give me feedback to </span>
<span class="co"># ## better help you!! :) Amy</span></code></pre></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Amy Willis, Kathryn Barger, John Bunge.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
